---
title: "Prediction Assignment Writeup"
author: "Charmeine Ko"
date: "6/29/2020"
output: html_document
---

This project aims to analyze data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The resulted data is used to quantify how well they performed the tasks.  
More detailed information is available [here](http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load Libraries and Download Data
```{r prep, message=FALSE, cache=TRUE}
set.seed(42)
# Load library
require(caret)
require(rattle)
# Load data
link_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
dat <- read.csv(link_train, na.strings=c("","NA"))
link_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
pml_test <- read.csv(link_test, na.strings=c("","NA"))
```

### Clean up and Preprocess Data
Several columns contain NA only, so we will remove them prior to analysis. In addition, irrelevant information such as *X*, *user_name*, *raw_timestamp_part_1*, *raw_timestamp_part_2*, *cvtd_timestamp*, *new_window*, *num_window* will also be omitted.  
```{r preprocessing, message=FALSE}
# Remove columns containing NA only and irrelevant information, i.e. column 1-7
clean <- dat[,colSums(is.na(dat))==0] 
clean <- clean[,-c(1:7)]

# Split into training and testing sets
train_part <- caret::createDataPartition(clean$classe, p=0.70, list=F)
train <- clean[train_part,]
test <- clean[-train_part,]
```

### Model Fitting
#### 1. Regression Trees
```{r rpart, message=FALSE, cache=TRUE}
fit_rpart <- train(classe ~ ., data = train, method = "rpart")
pred_rpart <- predict(fit_rpart, test)
confusionMatrix(test$classe, pred_rpart)
fancyRpartPlot(fit_rpart$finalModel)
```

Regression Trees result in high out-of-sample error, for the accuracy is approximately at 0.5, roughly equivalent to random chance.

#### 2. Linear Discriminant Analysis (LDA)
```{r lda, message=FALSE, cache=TRUE}
fit_lda <- train(classe ~ ., data = train, method = "lda")
pred_lda <- predict(fit_lda, test)
confusionMatrix(test$classe, pred_lda)
```
The out-of-sample error of LDA is lower than Regression Tree, achieving an accuracy of around 0.7.

#### 3. Random Forest
```{r rf, message=FALSE, cache=TRUE}
fit_rf <- train(classe ~ ., data = train, prox = TRUE, method = "rf", ntrees = 100)
pred_rf <- predict(fit_rf, test)
confusionMatrix(test$classe, pred_rf)
```

Random forest results in the highest accuracy and thus the lowest out-of-sample error among all the models tested, so it will be used for the prediction task.

### Prediction
```{r pred, message=FALSE, cache=TRUE}
predict(fit_rf, pml_test)
```